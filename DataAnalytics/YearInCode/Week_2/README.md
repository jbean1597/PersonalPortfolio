# Week 2: Languages of the World
## Data
* Source: United Nations Statistics Division
  - [Population by language, sex and urban/rural residence](https://data.un.org/Data.aspx?q=language&d=POP&f=tableCode%3a27#POP)
  - Last updated: 2022/02/11
## The Problem
While there is not a "problem" per se to be solved with this week's dataset, that doesn't mean interesting insights and visualizations can't be drawn from it. I have a deep interest in languages, whether that be learning them or being amazed at the variety between languages while still sharing so many similarities, so a dataset that allows me to combine both passions of mine would be a great choice for me!  

## Day 1: Ask
* Does proximity influence languages spoken in that region? (i.e. are borders a discerning factor in defining the languages spoken?)
* Do languages that are geographically close share more similarities?
* How do languages migrate and spread?
* What languages are the most common and also which are the most widespread? Which are the most localized/most resistant to globalization?
* **Hypotheses:** Proximity and similarities will share a strong relationship, perhaps the strongest determining factor. English will be the most widespread language while Mandarin will be one of the least widespread languages, possibly behind some much less common languages

## Day 2: Prepare
### Objectives
* What data needs to be collected and where will it come from?
  - Data concerning the relationships of languages and the phonetics of them
  - Data for the geographical area of a language and population demographics
* Where is the data located?
  - The World Atlas of Language Structures (WALS)
  - UN Statistics Division
* What needs to be figured out and how will it be done?
  - Language families need to be visualized geographically
  - Level of relation between languages through phonetics
  - Level of spread of a laguage through migration and familial relationships

## Day 3: Process
### Objectives 
* Clean data and establish a framework for what to remove/clean and what shouldn't be affected
* Remove null values
* Standardize some values in the datasets for easier analysis

See the whole process of cleaning and processing the data [here](https://github.com/jbean1597/PersonalPortfolio/blob/main/DataAnalytics/YearInCode/Week_2/Day_3.md)
